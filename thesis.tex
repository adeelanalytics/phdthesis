\documentclass[11pt]{book}

\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{lettrine}

\usepackage[commands,environments,enumerate,citations,notes,a4paper]{AVT}

\bibliography{citations}

\title{Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces}
\author{Alexander Terenin}
\date{August 2021}

\begin{document}

\begin{titlepage}
\maketitlehooka
\centering
\huge
\null
\vfill
\thetitle
\par
\vfill
\LARGE
\theauthor
\par
\large
Department of Mathematics
\par
Imperial College London
\par
\vfill
\null
\vfill
a dissertation submitted for the degree of
\par
Doctor of Philosophy
\par
\strut
\par
\thedate
\par
\vfill
\null
\maketitlehookd
\end{titlepage}

\chapter*{Declaration}

No more than 100,000 words

\chapter*{Copyright}

The copyright of this thesis rests with the author. Unless otherwise indicated, its contents are licensed under a Creative Commons Attribution 4.0 International Licence (CC BY).

Under this licence, you may copy and redistribute the material in any medium or format for both commercial and non-commercial purposes. You may also create and distribute modified versions of the work. This on the condition that you credit the author.

When reusing or sharing this work, ensure you make the licence terms clear to others by naming the licence and linking to the licence text. Where a work has been adapted, you should indicate that the work has been changed and describe those changes.

Please seek permission from the copyright holder for uses of this work that are not included in this licence or permitted under UK Copyright Law.

\chapter*{Acknowledgments}

\chapter*{Abstract}

Not more than 300 words

\tableofcontents





\chapter{Introduction}

\lettrine{L}{earning} from experience in order to change behavior is one of the defining abilities of biological systems, which differentiates them from other kinds of systems found in the world.
Replicating the processes biological systems use to learn and adapt is a fundamental goal of science and technology.
Realizing this goal would enable humanity to build automated systems to perform a significant quantity of the work currently done manually by ordinary people.
This could enable the average person to, in principle, spend significantly more time with their loved ones, or on pursuing personal interests.
The consequences of such developments are uncertain: what is much more clear, at present, is that humanity has a ways to go before our understanding of machine learning and artificial intelligence reachs a sufficient degree of command that visions such as the one presented here to become anything more than hypothetical.

The development of mathematical formalisms that are rich enough to capture many forms of \emph{learning} is one of the crowning achievements of machine learning, statistics, and artificial intelligence.
One such formalism is the \emph{Bayesian} view of learning, which defines learning as the computation of conditional probabilities.
Within the Bayesian framework, if one wants to reason about a quantity of interest on the basis of data, one needs only to introduce a probability distribution, known as the \emph{prior}, which describes the information known about the quantity of interest external to the data, and a conditional probability distribution, known as the \emph{likelihood}, which describes the relationship between the quantity of interest and the data.
Provided an appropriate setting to ensure these notions make rigorous sense is available, once the prior and likelihood are specified, and the data is observed, by Bayes' Rule, the information learned from the data is given as the conditional probability distribution of the quantity of interest given the data, which is known as the \emph{posterior} distribution.
In this formalism, to \emph{learn} is to compute posterior distributions.

The Bayesian view of learning is very powerful---in a sense, even too powerful for many problems, where it leads to computational problems that are intractable---sometimes, provably so.
A posterior distribution generally contains more information about the quantity of interest than one may actually want to know.
Specifically, if an abstract agent is interested in making decisions in pursuit of a goal, they may not need to know the expectation of all posterior expectations within a suitably-large function class in order to make the decision: a small finite set of expectations may suffice.
Making such statements precise leads one to consider a Bayesian theory of \emph{decision} built atop the introduced notion of learning.
Indeed, the ability to use Bayesian learning to construct a rigorous notion of decision-making in pursuit of a goal is one of the key properties that gives Bayesian theory its richness.

The performance of a decision system can be evaluated by examining how quickly its decisions improve and become optimal.
More precisely, a decision system's \emph{regret} is the reduction in its quality of decisions by virtue of not knowing the quantity of interest in advance.
In most non-trivial settings, one can show that some regret is inevitable: a decision-making system must make some degree of mistakes in order to learn.
A decision system is considered \emph{optimal} if its regret is within a constant factor of the best possible regret.

Decisions systems with optimal or close-to-optimal regret require less data in order to solve their respective tasks, and are called \emph{data-efficient}.
Data-efficiency is a key concern in practical settings, where data-collection takes time and can be expensive.
If computational costs are often the limiting factor of Bayesian decision systems, then data-efficiency is what is generally gained by paying those costs.
This makes Bayesian decision systems attractive settings where their strengths---including data-efficiency, solid technical foundations, and amenability to analysis---can shine, while computational costs are kept under control.

In my view, \emph{Gaussian processes} are one such setting: they are powerful enough to be the model wide classes of unknown quantities of interest, yet their computational costs are generally polynomial.
Better yet, Gaussian-processes-based decision systems have been demonstrated to exhibit excellent performance---sometimes, even provably so---in a number of practical settings, including ones deployed in real-world commercial applications.
Studying Gaussian processes is therefore a promising avenue towards improved understanding of Bayesian learning and Bayesian decision-making in pursuit of artificial intelligence.

The goal of this dissertation is twofold: (i) to make Gaussian processes easier to work with through improved numerical methods, particularly in cases where the Gaussian process is used within a larger decision system, and (ii) to expand the set of settings where Gaussian processes can be practically employed in, enabling construction of new decision systems, including for applications not previously considered.
Contributions toward (i) include path-wise conditioning techniques, which are studied in Chapter \ref{ch:pathwise}, and contributions toward (ii) include non-Euclidean Gaussian processes constructed using spectral methods, which are studied in Chapter \ref{ch:noneuclidean}.
Following these, Chapter \ref{ch:conclusion} concludes.

We now proceed to precisely define the notions needed to study Bayesian decision systems in the Gaussian process setting.
Mirroring the ideas presented above, we first define Gaussian process models, and then define decision-theoretic notions atop these models for the specific tasks at hand.
The goal is to define the key notions and describe how one should think about them in the given setting---we begin with the former.

\section{Gaussian processes}

Here we describe the GP formalism from scratch, starting from the simplest and ending with the most general and abstract setting

\subsection{Gaussian random variables}

Gaussian density

\subsection{Gaussian random vectors}

Matrix square root

\subsection{Gaussian random functions}

Let $X$ be a set. 

\subsection{Gaussian processes in general vector spaces}

Duality

Covariance form

Covariance operator

\section{Bayesian learning}

Posterior

Variational inference

\section{Statistical decision-making}

Decision

\subsection{Multi-armed bandits}

Setup

Basic regret analysis

\subsection{Bayesian optimization}

Setup

Regret analysis

\section{Contributions}

This work is either published or under review: \textcite{wilson20,borovitskiy20,borovitskiy21,wilson21,hutchinson21}.



\chapter{Pathwise Conditioning}
\label{ch:pathwise}

\section{Introduction}

The standard view of GP conditioning is to think about distributions

In the early 1970s, an alternative view emerged: work with RVs directly

This view, for whatever reason, never made it into the ML literature

This chapter of the thesis will explore its consequences and use it to solve what has been an open issue in Bayesian optimization for quite some time

The ideas in this chapter are published at ICML and JMLR

\section{Conditioning multivariate Gaussians}

Defn of MVN

\subsection{Distributional conditioning}

Formulas

Discussion

\subsection{Pathwise conditioning}

Formulas

Proof

Discussion

Second proof

Discussion

\section{Conditioning Gaussian processes}

Brief recollection of GPs 

\subsection{Distributional conditioning}

Formula

Discussion

\subsection{Pathwise conditioning}

Formula

Discussion

\section{Sampling from prior Gaussian processes}

The previous formula suggests an interesting class of approximations: discretize the prior

Finite basis expansion

This section: explore different expansions

\subsection{Random feature methods}

Construct a finite-dimensional feature map by discretizing the white noise integral

Closely related to stationarity in embedded spaces

\subsection{Karhunen--Lo√©ve expansions}

Alternatively: work with a different kind of spectral theory directly in the space

Obtain the KL expansion

\subsection{Finite element methods}

Completely different idea: represent GP as SPDE and solve the SPDE

Derivation

\section{Approximating pathwise data-dependent terms}

Previous part as about approximating the prior, which gets us to linear test-time costs

What about reinterpreting training-time costs from this viewpoint?

\subsection{Inducing points}

Reinterpret classical constructions

\subsection{Approximations which change the model}

RFF GP can be reinterpreted as replacing the prior with a finite-dim version

This results in unnecessarily large approximation error and variance starvation

\section{Error analysis}

Theorems

\section{Applications}

\subsection{Bayesian optimization}

Experiment

\section{Discussion}

Very useful technique for optimizing GP trajectories

Lets you do lots of awesome stuff

This work lets us understand it a lot better





\chapter{Non-Euclidean Mat√©rn Gaussian Processes}
\label{ch:noneuclidean}

\section{Riemannian Mat√©rn Gaussian Processes}

\subsection{Review of Riemannian geometry}
\subsection{The Laplace--Beltrami operator}
\subsection{A no-go theorem for kernels on manifolds}
\subsection{Stochastic partial differential equations}
\subsection{The Riemannian Mat√©rn kernel}
\subsection{Illustrated examples}

\section{Graph Mat√©rn Gaussian Processes}

\subsection{Review of graph theory}
\subsection{The graph Laplacian}
\subsection{The graph Mat√©rn kernel}
\subsection{Illustrated examples}

\section{Gaussian Vector Fields on Riemannian Manifolds}

\subsection{Review of vector fields on manifolds}
\subsection{Gauge-equivariant projected kernels}
\subsection{Illustrated examples}

\section{Discussion}
\label{sec:noneuclidean-discussion}





\chapter{Conclusion}
\label{ch:conclusion}

\printbibliography

\end{document}
