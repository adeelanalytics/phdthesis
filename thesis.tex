\documentclass[11pt]{book}

\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{lettrine}

\usepackage[commands,environments,enumerate,citations,notes,a4paper]{AVT}

\bibliography{citations}

\title{Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces}
\author{Alexander Terenin}
\date{August 2021}

\begin{document}

\begin{titlepage}
\maketitlehooka
\centering
\huge
\null
\vfill
\thetitle
\par
\vfill
\LARGE
\theauthor
\par
\large
Department of Mathematics
\par
Imperial College London
\par
\vfill
\null
\vfill
a dissertation submitted for the degree of
\par
Doctor of Philosophy
\par
\strut
\par
\thedate
\par
\vfill
\null
\maketitlehookd
\end{titlepage}

\chapter*{Declaration}

No more than 100,000 words

\chapter*{Copyright}

The copyright of this thesis rests with the author. Unless otherwise indicated, its contents are licensed under a Creative Commons Attribution 4.0 International Licence (CC BY).

Under this licence, you may copy and redistribute the material in any medium or format for both commercial and non-commercial purposes. You may also create and distribute modified versions of the work. This on the condition that you credit the author.

When reusing or sharing this work, ensure you make the licence terms clear to others by naming the licence and linking to the licence text. Where a work has been adapted, you should indicate that the work has been changed and describe those changes.

Please seek permission from the copyright holder for uses of this work that are not included in this licence or permitted under UK Copyright Law.

\chapter*{Acknowledgments}

\chapter*{Abstract}

Not more than 300 words

\tableofcontents





\chapter{Introduction}

\lettrine{L}{earning} from experience in order to change behavior is one of the defining abilities of biological systems, which differentiates them from other kinds of systems found in the world.
Replicating the processes biological systems use to learn and adapt is a fundamental goal of science and technology.
Realizing this goal would enable humanity to build automated systems to perform a significant quantity of the work currently done manually by ordinary people.
This could enable the average person to, in principle, spend significantly more time with their loved ones, or on pursuing personal interests.
Though the precise consequences of such developments are uncertain, at present, it is clear that humanity has a ways to go before our understanding of machine learning and artificial intelligence reaches a sufficient degree of command that visions such as the one presented here to become anything more than hypothetical.

The development of mathematical formalisms that are rich enough to capture many forms of \emph{learning} is one of the crowning achievements of machine learning, statistics, and artificial intelligence.
One such formalism is the \emph{Bayesian} view of learning, which defines learning as the computation of conditional probabilities.
Within the Bayesian framework, if one wants to reason about a quantity of interest on the basis of data, one needs only to introduce a probability distribution, known as the \emph{prior}, which describes the information known about the quantity of interest external to the data, and a conditional probability distribution, known as the \emph{likelihood}, which describes the relationship between the quantity of interest and the data.
Provided an appropriate setting to ensure these notions make rigorous sense is available, once the prior and likelihood are specified, and the data is observed, by Bayes' Rule, the information learned from the data is given as the conditional probability distribution of the quantity of interest given the data, which is known as the \emph{posterior} distribution.
In this formalism, to \emph{learn} is to compute posterior distributions.

The Bayesian view of learning is very powerful---in a sense, even too powerful for many problems, where it leads to computational problems that are intractable---sometimes, provably so.
A posterior distribution generally contains more information about the quantity of interest than one may actually want to know.
Specifically, if an abstract agent is interested in making decisions in pursuit of a goal, they may not need to know the expectation of all posterior expectations within a suitably-large function class in order to make the decision: a small finite set of expectations may suffice.
Making such statements precise leads one to consider a Bayesian theory of \emph{decision} built atop the introduced notion of learning.
Indeed, the ability to use Bayesian learning to construct a rigorous notion of decision-making in pursuit of a goal is one of the key properties that gives Bayesian theory its richness.

The performance of a decision system can be evaluated by examining how quickly its decisions improve and become optimal.
More precisely, a decision system's \emph{regret} is the reduction in its quality of decisions by virtue of not knowing the quantity of interest in advance.
In most non-trivial settings, one can show that some regret is inevitable: a decision-making system must make some degree of mistakes in order to learn.
A decision system is considered \emph{optimal} if its regret is within a constant factor of the best possible regret.

Decisions systems with optimal or close-to-optimal regret require less data in order to solve their respective tasks, and are called \emph{data-efficient}.
Data-efficiency is a key concern in practical settings, where data-collection takes time and can be expensive.
If computational costs are often the limiting factor of Bayesian decision systems, then data-efficiency is what is generally gained by paying those costs.
This makes Bayesian decision systems attractive settings where their strengths---including data-efficiency, solid technical foundations, and amenability to analysis---can shine, while computational costs are kept under control.

In my view, \emph{Gaussian processes} are one such setting: they are powerful enough to model wide classes of unknown quantities of interest, yet their computational costs are generally polynomial.
Better yet, Gaussian-processes-based decision systems have been demonstrated to exhibit excellent performance---sometimes, even provably so---in a number of practical settings, including ones deployed in real-world commercial applications.
Studying Gaussian processes is therefore a promising avenue towards improved understanding of Bayesian learning and Bayesian decision-making in pursuit of artificial intelligence.

The goals of this dissertation are twofold: (i) to make Gaussian processes easier to work with through improved numerical methods, particularly in cases where the Gaussian process is used within a larger decision system, and (ii) to expand the set of settings where Gaussian processes can be practically employed in, enabling construction of new decision systems, including for applications not previously considered.
Contributions toward (i) include path-wise conditioning techniques, which are studied in Chapter \ref{ch:pathwise}, and contributions toward (ii) include non-Euclidean Gaussian processes constructed using spectral methods, which are studied in Chapter \ref{ch:noneuclidean}.
Following these, Chapter \ref{ch:conclusion} concludes.

To pursue these goals, it is critically important that all of the ideas described in the preceding paragraphs be made into rigorous mathematics, so that the ideas described in the sequel ultimately reduce to definitions and implications, and not metaphor or opinion.
I will therefore begin by defining the appropriate mathematical notions need subsequently, starting from an assumed background knowledge of measure-theoretic probability and functional analysis for Chapter \ref{ch:pathwise}, and, in addition, differential geometry for Chapter \ref{ch:noneuclidean}.
My presentation will mirror the structure presented previously, and begin with models, before moving to decision-theoretic notions defined atop said models for the specific tasks at hand.
I will strive to both define the key notions, and describe how one should think about them in the given setting, beginning with the so far omitted description of what a Gaussian process is.

\section{Gaussian processes}

A Gaussian process can be thought of as a collection of random variables which, no matter what angle one views them from, yield Gaussian marginal distributions.
In the following, I will describe a formalism for making this description precise, starting from the simplest setting possible before moving to increasing levels of abstraction and generality.
Our goal will be to develop the notion of a Gaussian process $f : \Omega \-> V$ where $(\Omega,\c{F},\P)$ is a probability space and $V$ is a real topological vector space, almost always equipped with additional structure.
Gaussian process are fundamentally \emph{linear} objects which reflect the structure of the topological vector spaces over which they are defined.
The simplest settings arise when $V$ is smallest.

\1  Choosing $V = \{0\}$ to be the trivial vector space, there is exactly one $V$-valued random variable, whose distribution is the Dirac measure centered at $0$, which can trivially be called Gaussian.
This random variable is not very interesting, so we do not consider it further.
\2 Choosing $V = \R$ to coincide with the underlying scalar field yields the setting of \emph{Gaussian random variables}.
This is the next-simplest setting and the first one we explore in detail.
\3 Choosing $V = \R^d$ yields the setting of \emph{Gaussian random vectors}, whose components are multivariate Gaussian---or, equivalently, whose \emph{dot products} are scalar-valued Gaussian---an alternative view which will become important later.
\4 Choosing $V$ to be a suitable vector space of functions $f : X \-> \R$ yields the setting of Gaussian processes, whose finite-dimensional marginals are multivariate Gaussian.
This setting is well-studied when $X$ is itself a Euclidean space: in Chapter \ref{ch:noneuclidean}, we will examine cases where $X$ instead possesses geometric structure inherited by the Gaussian process.
\5 Finally, choosing $V$ to be a possibly infinite-dimensional vector space, such as a Banach of Hilbert space---this yields the most general setting we examine.
This level of generality will be important for two reasons: (i) to develop a coordinate-free notion of Gaussian random vectors that will be useful in the differential-geometric setting, and (ii) to develop a formalism rich enough to define white noise processes, which will be needed in Chapter \ref{ch:noneuclidean}.
\0 

We proceed to examine the scalar case.

\subsection{Gaussian random variables}

A Gaussian random variable is a map which takes in an abstract random number, and returns a real scalar.
To begin formalizing this notion, let $(\Omega,\c{F},\P)$ be a probability space, and here and henceforth, equip all topological vector spaces with their respective Borel $\sigma$-algebras. 
The basic object from which other Gaussians will be constructed is the standard scalar Gaussian, defined as follows.

\begin{definition}[Standard Gaussian random variable]
A random variable $z : \Omega\->\R$ is called \emph{standard Gaussian} if it admits the Lebesgue density
\[
f(z) = \frac{1}{\sqrt{2\pi}} \exp\del{-\frac{z^2}{2}}
.
\]
\end{definition}

From this, we define general scalar Gaussians.

\begin{definition}[Gaussian random variable]
A random variable $y : \Omega\->\R$ is called \emph{Gaussian} if there are scalars $\mu, \sigma\in\R$, and a standard Gaussian $z$, such that
\[
y = \sigma z + \mu
.
\]
\end{definition}

Note that we do \emph{not} require $\sigma \geq 0$: hence, every Gaussian random variable is determined uniquely in 
distribution by the pair $(\mu,\sigma^2)$, which we call its \emph{mean} and \emph{variance}, respectively. 
We write $y \~[N](\mu,\sigma^2)$.
True to these parameter names, we have
\[
\E(y) &= \mu
&
\E\del{(y - \mu)^2} &= \sigma^2
.
\]
A Gaussian random variable is called \emph{centered} if $\mu = 0$.
For a given variance $\sigma^2$ and standard Gaussian $z$, the expressions $\sigma z$ and $-\sigma z$ define two \emph{different} centered Gaussians with the same distribution.
At this stage, pointing these distinctions may appear needlessly pedantic: they will become more pronounced and important once we consider more general objects.
The density of a Gaussian random variable, if it exists, takes on a form analogous to that of a standard Gaussian, namely
\[
f(y) = \frac{1}{\sqrt{2\pi}\sigma} \exp\del{-\frac{(y-\mu)^2}{2\sigma^2}}
.
\]
which shows that the densities of Gaussian random variables respect the additive and multiplicative structures of the reals---this compatibility with linear structure will be true at all levels of generality we consider.
Note that the density will not exist if $\sigma^2 = 0$: the distributions of such Gaussians are Dirac measures centered at $\mu$.
We are now ready to lift this definition to construct multivariate analogs.

\subsection{Gaussian random vectors}

A multivariate Gaussian random vector is a random variable taking values in $\R^d$.
We will distinguish $\R^d$ from a generic $d$-dimensional vector space: the former comes with a product structure $\R^d = \R \x .. \x \R$ which includes projection maps onto each coordinate, which in turn induce a \emph{canonical} choice of inner product given by the Euclidean dot product.
A generic finite-dimensional vector space lacks this structure: it admits many different inner products, and provides for no canonical choice---this difference will become important in the sequel.
We write vectors defined in $\R^d$ in bold italics to emphasize this distinction, and similarly distinguish matrices from linear maps by writing the former in bold upface letters.
As before, we begin by defining a standard Gaussian, which we note is an inner-product-dependent notion.

\begin{definition}[Standard multivariate Gaussian random variable]
A random variable $\v{z} : \Omega\->\R^d$ is called \emph{standard multivariate Gaussian} if if its distribution is the product measure of the distributions of $d$ standard Gaussians.
\end{definition}

One can easily see that this definition works in $\R^d$, but fails in a generic finite-dimensional vector space $V$ unless it is equipped with an inner product.
If $V$ does admit an inner product, a standard Gaussian can be defined by choosing an orthonormal basis with respect to the given inner product, adapting the above definition, and showing that it is well-defined by virtue of not depending on the choice of basis.
This is easy to see, since linear maps associated with changes of orthonormal bases are represented by orthogonal matrices.
As before, we will again define multivariate Gaussians as transformations of standard Gaussians.

\begin{definition}[Multivariate Gaussian random variable]
A random variable $\v{y} : \Omega\->\R^d$ is called \emph{multivariate Gaussian} if there is a vector $\v\mu\in\R^d$, matrix $\m{L}\in\R^{d\x d}$, and standard multivariate Gaussian $\v{z}$, such that
\[
\v{y} = \m{L}\v{z} + \v\mu
.
\]
\end{definition}

Every multivariate Gaussian is determined by its \emph{mean vector} $\v\mu$ and positive semi-definite \emph{covariance matrix} $\m\Sigma = \m{L}\m{L}^T$, and, as before, is called \emph{centered} if $\v\mu = \v{0}$.
We write $\v{y}\~[N](\v\mu,\m\Sigma)$ can obtain a centered multivariate Gaussian with a given distribution by calculating a \emph{matrix square root} of $\m\Sigma$, multiplying it with a standard Gaussian.
Just as before, we have
\[
\E(\v{y}) &= \v\mu    
&
\Cov(\v{y}) &= \E\del{(\v{y}-\v\mu)(\v{y}-\v\mu)^T} = \m\Sigma
\]
and, if the determinant $|\m\Sigma|$ is non-zero,
\[
f(\v{y}) = \frac{1}{\sqrt{(2\pi)^d|\m\Sigma|}} \exp\del{-\frac{1}{2}(\v{y}-\v\mu)^T\m\Sigma^{-1}(\v{y}-\v\mu)}
\]
which now might not exist even if the distribution of $\v{y}$ is not Dirac.
In such cases, one can see that at least some of the eigenvalues of $\m\Sigma$ must be zero, and so Gaussians which do not admit densities must, when viewed in an appropriate basis, be products of Dirac measures with Gaussians which do admit densities.
Already in the multivariate case, then, we see the technical power of densities weakening: this behavior will become even more pronounced as we consider more general settings, which we now proceed to study.


\subsection{Gaussian random functions}

Let $X$ be a set. 

\subsection{Gaussian processes in general vector spaces}

Duality

Covariance form

Covariance operator

\section{Bayesian learning}

Posterior

Variational inference

\section{Statistical decision-making}

Decision

\subsection{Multi-armed bandits}

Setup

Basic regret analysis

\subsection{Bayesian optimization}

Setup

Regret analysis

\section{Contributions}

This work is either published or under review: \textcite{wilson20,borovitskiy20,borovitskiy21,wilson21,hutchinson21}.



\chapter{Pathwise Conditioning}
\label{ch:pathwise}

\section{Introduction}

The standard view of GP conditioning is to think about distributions

In the early 1970s, an alternative view emerged: work with RVs directly

This view, for whatever reason, never made it into the ML literature

This chapter of the thesis will explore its consequences and use it to solve what has been an open issue in Bayesian optimization for quite some time

The ideas in this chapter are published at ICML and JMLR

\section{Conditioning multivariate Gaussians}

Defn of MVN

\subsection{Distributional conditioning}

Formulas

Discussion

\subsection{Pathwise conditioning}

Formulas

Proof

Discussion

Second proof

Discussion

\section{Conditioning Gaussian processes}

Brief recollection of GPs 

\subsection{Distributional conditioning}

Formula

Discussion

\subsection{Pathwise conditioning}

Formula

Discussion

\section{Sampling from prior Gaussian processes}

The previous formula suggests an interesting class of approximations: discretize the prior

Finite basis expansion

This section: explore different expansions

\subsection{Random feature methods}

Construct a finite-dimensional feature map by discretizing the white noise integral

Closely related to stationarity in embedded spaces

\subsection{Karhunen--Loéve expansions}

Alternatively: work with a different kind of spectral theory directly in the space

Obtain the KL expansion

\subsection{Finite element methods}

Completely different idea: represent GP as SPDE and solve the SPDE

Derivation

\section{Approximating pathwise data-dependent terms}

Previous part as about approximating the prior, which gets us to linear test-time costs

What about reinterpreting training-time costs from this viewpoint?

\subsection{Inducing points}

Reinterpret classical constructions

\subsection{Approximations which change the model}

RFF GP can be reinterpreted as replacing the prior with a finite-dim version

This results in unnecessarily large approximation error and variance starvation

\section{Error analysis}

Theorems

\section{Applications}

\subsection{Bayesian optimization}

Experiment

\section{Discussion}

Very useful technique for optimizing GP trajectories

Lets you do lots of awesome stuff

This work lets us understand it a lot better





\chapter{Non-Euclidean Matérn Gaussian Processes}
\label{ch:noneuclidean}

\section{Riemannian Matérn Gaussian Processes}

\subsection{Review of Riemannian geometry}
\subsection{The Laplace--Beltrami operator}
\subsection{A no-go theorem for kernels on manifolds}
\subsection{Stochastic partial differential equations}
\subsection{The Riemannian Matérn kernel}
\subsection{Illustrated examples}

\section{Graph Matérn Gaussian Processes}

\subsection{Review of graph theory}
\subsection{The graph Laplacian}
\subsection{The graph Matérn kernel}
\subsection{Illustrated examples}

\section{Gaussian Vector Fields on Riemannian Manifolds}

\subsection{Review of vector fields on manifolds}
\subsection{Gauge-equivariant projected kernels}
\subsection{Illustrated examples}

\section{Discussion}
\label{sec:noneuclidean-discussion}





\chapter{Conclusion}
\label{ch:conclusion}

\printbibliography

\end{document}
